{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "from sklearn.linear_model import ElasticNet\n",
        "def train_models_and_save(df_drug):\n",
        "    # Initialize LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Encode categorical features\n",
        "    categorical_features = [feature for feature in df_drug.columns if df_drug[feature].dtypes == 'O']\n",
        "    for feature in categorical_features:\n",
        "        df_drug[feature] = label_encoder.fit_transform(df_drug[feature])\n",
        "\n",
        "    # Define X and y\n",
        "    X = df_drug.drop(\"Drug\", axis=1)\n",
        "    y = df_drug[\"Drug\"]\n",
        "\n",
        "    # Train Decision Tree model\n",
        "    dt_model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "    dt_model.fit(X, y)\n",
        "\n",
        "    # Train SVM model\n",
        "    svm_model = SVC(kernel='rbf')\n",
        "    svm_model.fit(X, y)\n",
        "\n",
        "    # Train Logistic Regression model\n",
        "    lr_model = LogisticRegression()\n",
        "    lr_model.fit(X, y)\n",
        "\n",
        "    # Save models to disk\n",
        "    with open('dt_model.pkl', 'wb') as dt_file:\n",
        "        pickle.dump(dt_model, dt_file)\n",
        "\n",
        "    with open('svm_model.pkl', 'wb') as svm_file:\n",
        "        pickle.dump(svm_model, svm_file)\n",
        "\n",
        "    with open('lr_model.pkl', 'wb') as lr_file:\n",
        "        pickle.dump(lr_model, lr_file)\n",
        "\n",
        "def predict_drug_with_models(Age, Sex, BP, Cholesterol, Na_to_K):\n",
        "    # Load models from disk\n",
        "    with open('dt_model.pkl', 'rb') as dt_file:\n",
        "        dt_model = pickle.load(dt_file)\n",
        "\n",
        "    with open('svm_model.pkl', 'rb') as svm_file:\n",
        "        svm_model = pickle.load(svm_file)\n",
        "\n",
        "    with open('lr_model.pkl', 'rb') as lr_file:\n",
        "        lr_model = pickle.load(lr_file)\n",
        "\n",
        "    # Transform categorical variables to numerical values\n",
        "    Sex = gender_map[Sex]\n",
        "    BP = bp_map[BP]\n",
        "    Cholesterol = cholestol_map[Cholesterol]\n",
        "\n",
        "    # Make predictions using all models\n",
        "    dt_prediction = dt_model.predict([[Age, Sex, BP, Cholesterol, Na_to_K]])[0]\n",
        "    svm_prediction = svm_model.predict([[Age, Sex, BP, Cholesterol, Na_to_K]])[0]\n",
        "    lr_prediction = lr_model.predict([[Age, Sex, BP, Cholesterol, Na_to_K]])[0]\n",
        "\n",
        "    # Map numerical predictions to drug names\n",
        "    dt_drug = drug_map[dt_prediction]\n",
        "    svm_drug = drug_map[svm_prediction]\n",
        "    lr_drug = drug_map[lr_prediction]\n",
        "\n",
        "    return dt_drug, svm_drug, lr_drug\n",
        "\n",
        "def calculate_accuracy(model, X, y):\n",
        "    kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=\"accuracy\")\n",
        "    return cv_results.mean(), cv_results.std()\n",
        "\n",
        "# Load the dataset\n",
        "df_drug = pd.read_csv(\"/content/drug200.csv\")\n",
        "\n",
        "# Train models and save to disk\n",
        "train_models_and_save(df_drug)\n",
        "\n",
        "# Example usage\n",
        "predicted_drug_dt, predicted_drug_svm, predicted_drug_lr = predict_drug_with_models(54, \"M\", \"LOW\", \"NORMAL\", 14)\n",
        "print(\"Predicted drug using Decision Tree:\", predicted_drug_dt)\n",
        "print(\"Predicted drug using SVM:\", predicted_drug_svm)\n",
        "print(\"Predicted drug using Logistic Regression:\", predicted_drug_lr)\n",
        "\n",
        "# Calculate accuracy for Decision Tree model\n",
        "X = df_drug.drop(\"Drug\", axis=1)\n",
        "y = df_drug[\"Drug\"]\n",
        "dt_model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "dt_accuracy_mean, dt_accuracy_std = calculate_accuracy(dt_model, X, y)\n",
        "print(\"Accuracy using Decision Tree:\", dt_accuracy_mean, dt_accuracy_std)\n",
        "\n",
        "# Calculate accuracy for SVM model\n",
        "svm_model = SVC(kernel='rbf')\n",
        "svm_accuracy_mean, svm_accuracy_std = calculate_accuracy(svm_model, X, y)\n",
        "print(\"Accuracy using SVM:\", svm_accuracy_mean, svm_accuracy_std)\n",
        "\n",
        "# Calculate accuracy for Logistic Regression model\n",
        "lr_model = LogisticRegression()\n",
        "lr_accuracy_mean, lr_accuracy_std = calculate_accuracy(lr_model, X, y)\n",
        "print(\"Accuracy using Logistic Regression:\", lr_accuracy_mean, lr_accuracy_std)\n",
        "\n",
        "\n",
        "#Naive bayes classifer implemented\n",
        "# Initialize the Naive Bayes classifier (Gaussian Naive Bayes for continuous features)\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "nb_classifier.fit(X,y)\n",
        "\n",
        "# Predictions\n",
        "y_pred = nb_classifier.predict(X)\n",
        "\n",
        "# Model evaluation\n",
        "accuracy = accuracy_score(y,y_pred)\n",
        "print(\"Accuracy using Naive Bayes Classfier:\", accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnz05smVGkrP",
        "outputId": "6ad2a89c-7826-413a-e504-d6aba8028560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted drug using Decision Tree: drugX\n",
            "Predicted drug using SVM: drugX\n",
            "Predicted drug using Logistic Regression: drugX\n",
            "Accuracy using Decision Tree: 0.99 0.012247448713915901\n",
            "Accuracy using SVM: 0.705 0.07314369419163898\n",
            "Accuracy using Logistic Regression: 0.86 0.046368092477478536\n",
            "Accuracy using Naive Bayes Classfier: 0.865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "dataset = pd.read_csv(\"/content/drug200.csv\")\n",
        "datah = dataset.replace('?')\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "datahNew = datah.dropna()\n",
        "datahNew\n",
        "\n",
        "x = datahNew[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']]\n",
        "y = datahNew['Drug']\n",
        "\n",
        "print (pd.unique(x['Sex']))\n",
        "print (pd.unique(x['BP']))\n",
        "print (pd.unique(x['Cholesterol']))\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "x['Sex'] = le.fit_transform(x['Sex'])\n",
        "x['BP'] = le.fit_transform(x['BP'])\n",
        "x['Cholesterol'] = le.fit_transform(x['Cholesterol'])\n",
        "\n",
        "x.shape\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.25, random_state = 0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.fit_transform(x_test)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 2,metric = 'euclidean',p=2)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "neighbors = np.arange(1, 10)\n",
        "train_accuracy = np.empty(len(neighbors))\n",
        "test_accuracy =np.empty(len(neighbors))\n",
        "#Loop over x values\n",
        "\n",
        "for i, k in enumerate (neighbors):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(x_train, y_train)\n",
        "\n",
        "#Compute traning and test data accuracy\n",
        "\n",
        "train_accuracy[1]=  knn.score(x_train, y_train)\n",
        "test_accuracy[1] = knn.score(x_test, y_test)\n",
        "\n",
        "error_rate = []\n",
        "for i in range(1,40):\n",
        "    knn = KNeighborsClassifier(n_neighbors=1)\n",
        "    knn.fit(x_train,y_train)\n",
        "    pred_i= knn.predict(x_test)\n",
        "    error_rate.append(np.mean(pred_i != y_test))\n",
        "print(\"Minimum error:-\",min(error_rate),\"at k=\",error_rate.index(min(error_rate)))\n",
        "\n",
        "acc = []\n",
        "from sklearn import metrics\n",
        "for i in range(1,40):\n",
        "    neigh = KNeighborsClassifier(n_neighbors=i).fit(x_train,y_train)\n",
        "    yhat = neigh.predict(x_test)\n",
        "    acc.append(metrics.accuracy_score(y_test, yhat))\n",
        "print(\"Maximum accuracy:\",max(acc), \"at K\", acc.index(max(acc)))\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=2, metric=\"euclidean\", p=2)\n",
        "classifier.fit(x_train,y_train)\n",
        "KNeighborsClassifier(metric=\"euclidean\", n_neighbors=2)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "df_pred = pd.DataFrame(y_pred)\n",
        "df_pred\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm=pd.DataFrame(cm)\n",
        "df_cm\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy using KNN:-\",accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeLmVT4TGp94",
        "outputId": "d960408e-42e6-4c41-b245-e124f3c777e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['F' 'M']\n",
            "['HIGH' 'LOW' 'NORMAL']\n",
            "['HIGH' 'NORMAL']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-e59b2cab67dc>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x['Sex'] = le.fit_transform(x['Sex'])\n",
            "<ipython-input-45-e59b2cab67dc>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x['BP'] = le.fit_transform(x['BP'])\n",
            "<ipython-input-45-e59b2cab67dc>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x['Cholesterol'] = le.fit_transform(x['Cholesterol'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum error:- 0.08 at k= 0\n",
            "Maximum accuracy: 0.92 at K 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       DrugY       0.96      0.96      0.96        25\n",
            "       drugA       0.83      1.00      0.91         5\n",
            "       drugB       0.33      1.00      0.50         1\n",
            "       drugC       1.00      1.00      1.00         3\n",
            "       drugX       1.00      0.81      0.90        16\n",
            "\n",
            "    accuracy                           0.92        50\n",
            "   macro avg       0.83      0.95      0.85        50\n",
            "weighted avg       0.95      0.92      0.93        50\n",
            "\n",
            "Accuracy using KNN:- 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RFclassifier = RandomForestClassifier(max_leaf_nodes=30)\n",
        "RFclassifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = RFclassifier.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "RFAcc = accuracy_score(y_pred,y_test)\n",
        "print('Random Forest accuracy is: {:.2f}%'.format(RFAcc*100))\n",
        "\n",
        "\n",
        "#ridge regression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "\n",
        "\n",
        "# Define and train the Ridge Classifier model\n",
        "ridge_clf = make_pipeline(StandardScaler(), RidgeClassifier(alpha=1.0))\n",
        "ridge_clf.fit(x_train, y_train)\n",
        "\n",
        "# Predict drug activity/toxicity on the test set\n",
        "y_pred = ridge_clf.predict(x_test)\n",
        "\n",
        "# Evaluate the model using accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy using RidgeClassifier:\",accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOmiJ8ssYHrb",
        "outputId": "d84a70e1-3be0-4be8-a0d6-bacbd0b6ec5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       DrugY       1.00      1.00      1.00        25\n",
            "       drugA       1.00      0.80      0.89         5\n",
            "       drugB       0.50      1.00      0.67         1\n",
            "       drugC       1.00      1.00      1.00         3\n",
            "       drugX       1.00      1.00      1.00        16\n",
            "\n",
            "    accuracy                           0.98        50\n",
            "   macro avg       0.90      0.96      0.91        50\n",
            "weighted avg       0.99      0.98      0.98        50\n",
            "\n",
            "[[25  0  0  0  0]\n",
            " [ 0  4  1  0  0]\n",
            " [ 0  0  1  0  0]\n",
            " [ 0  0  0  3  0]\n",
            " [ 0  0  0  0 16]]\n",
            "Random Forest accuracy is: 98.00%\n",
            "Accuracy using RidgeClassifier: 0.84\n"
          ]
        }
      ]
    }
  ]
}